{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54373d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc876ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bdudas/anaconda3/envs/vcell/lib/python3.10/site-packages/pytorch_lightning/__init__.py:82: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__('pkg_resources').declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.dataset_highvars import get_loader\n",
    "from dataclasses import dataclass\n",
    "import anndata as ad\n",
    "from torch.utils.data import Dataset\n",
    "import scanpy as sc\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27894951",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf68423",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    log_dir = \"logs\"\n",
    "    name = \"AttentionDiffuse\"\n",
    "    batch_size = 64 # Genes processed at once\n",
    "    version = 1\n",
    "    epochs = 30\n",
    "    lr = 1e-3\n",
    "    num_workers = 15\n",
    "    num_samples = 700\n",
    "    target_gene_dim = 128\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82405597",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRoot = \"data/vcc_data\"\n",
    "tr_adata_path = f\"{dataRoot}/adata_Training.h5ad\"\n",
    "adata = ad.read_h5ad(tr_adata_path)\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "#sc.pp.highly_variable_genes(adata)\n",
    "#maskidx = (~adata.var.index.str.startswith(\"MT-\")) & adata.var.highly_variable\n",
    "#adata = adata[:,maskidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24dcc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_encoding_vector(pos, d_model):\n",
    "    \"\"\"\n",
    "    Calculates the positional encoding vector for a single position.\n",
    "    \n",
    "    Args:\n",
    "        pos (int): The position index (e.g., 0, 1, 2...).\n",
    "        d_model (int): The dimension of the embedding (e.g., 512).\n",
    "                       Must be an even number for this implementation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 1D array of shape (d_model,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure d_model is even for simplicity in pairing sin/cos\n",
    "    if d_model % 2 != 0:\n",
    "        raise ValueError(\"d_model must be an even number.\")\n",
    "\n",
    "    # 1. Create an array for all dimension indices: [0, 1, 2, ..., d_model-1]\n",
    "    d_indices = np.arange(d_model)\n",
    "\n",
    "    # 2. Calculate the 'i' term for the denominator: [0, 0, 1, 1, 2, 2, ...]\n",
    "    # This is the 'i' from the formula\n",
    "    i = d_indices // 2\n",
    "\n",
    "    # 3. Calculate the denominator (the \"timescale\" term)\n",
    "    # 10000^(2i / d_model)\n",
    "    denominator = np.power(10000, (2 * i) / d_model)\n",
    "\n",
    "    # 4. Calculate the angle for every dimension: pos / denominator\n",
    "    angles = pos / denominator\n",
    "    \n",
    "    # 5. Create the final vector\n",
    "    pe_vector = np.zeros(d_model)\n",
    "\n",
    "    # 6. Apply sin to all even indices\n",
    "    pe_vector[0::2] = np.sin(angles[0::2])\n",
    "\n",
    "    # 7. Apply cos to all odd indices\n",
    "    pe_vector[1::2] = np.cos(angles[1::2])\n",
    "\n",
    "    return torch.tensor(pe_vector).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12aeae72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentBatch = adata.obs.iloc[10].target_gene\n",
    "mask = adata.obs.batch == currentBatch\n",
    "mask.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c96399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneExpressionDataset(Dataset):\n",
    "    def __init__(self, adata,geneMapping,seqLength = 32):\n",
    "        mask = (adata.obs.target_gene != \"non-targeting\")\n",
    "        mask2 = (adata.obs.target_gene == \"non-targeting\")\n",
    "        \n",
    "        self.adata_X = adata[mask].X\n",
    "        self.adata_obs = adata[mask].obs\n",
    "        \n",
    "        self.adata_batchX = adata[mask2].X\n",
    "        self.adata_obs_batch = adata[mask2].obs\n",
    "        self.seqLength = seqLength\n",
    "        self.geneMapping = geneMapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.adata_X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get labels to convert to numbers\n",
    "        currentBatch = self.adata_obs.iloc[idx].batch\n",
    "        gene = self.adata_obs.iloc[idx].target_gene\n",
    "\n",
    "\n",
    "        gene_expression = self.adata_X[idx].toarray().squeeze()\n",
    "        gene_expressionseq = gene_expression.reshape(self.seqLength,-1)\n",
    "        \n",
    "        mask = self.adata_obs_batch[\"batch\"] == currentBatch\n",
    "        valid_indices = mask.to_numpy()\n",
    "        random_index = np.random.choice(valid_indices)\n",
    "        clean_expression = self.adata_batchX[random_index].toarray().squeeze()\n",
    "        \n",
    "        geneidx = self.geneMapping[gene]\n",
    "        \n",
    "        return gene_expressionseq, clean_expression.reshape(self.seqLength,-1), np.expand_dims(get_positional_encoding_vector(geneidx,self.seqLength),axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "genemap = {b:i for i,b in enumerate(adata.obs.target_gene.unique())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10abbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeneExpressionDataset(adata,genemap)\n",
    "trainDataset,valDataset = torch.utils.data.random_split(dataset,[int(0.8*len(dataset)),len(dataset)-int(0.8*len(dataset))])\n",
    "#implement k-fold later\n",
    "train_loader = torch.utils.data.DataLoader(trainDataset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
    "val_loader = torch.utils.data.DataLoader(valDataset, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59160447",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes, batchinfo, posencode = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30232e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 32, 565]), torch.Size([64, 32, 565]), torch.Size([64, 32, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes.shape, batchinfo.shape, posencode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf754516",
   "metadata": {},
   "source": [
    "# Design Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b3dfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a855679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = genes.shape[0]\n",
    "timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57053810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 565])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6447c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def timestep_embedding(t, dim):\n",
    "    \"\"\"\n",
    "    t: (batch,)\n",
    "    dim: embedding dimension\n",
    "    \"\"\"\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        torch.arange(half, dtype=torch.float32) * -(math.log(10000) / half)\n",
    "    ).to(t.device)\n",
    "    args = t[:, None].float() * freqs[None]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    return emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38f25c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Uattention(nn.Module):\n",
    "    def __init__(self,inDims,outDims,condDIm = 1):\n",
    "        super().__init__()\n",
    "        self.qlayer = nn.Linear(inDims,outDims)\n",
    "        self.klayer = nn.Linear(condDIm,outDims)\n",
    "        self.vlayer = nn.Linear(condDIm,outDims)\n",
    "        self.mha = nn.MultiheadAttention(embed_dim = outDims,num_heads=8,batch_first=True) # Might be scaled\n",
    "        self.norm = nn.LayerNorm(outDims)\n",
    "        self.time_proj = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64, inDims)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x,conditioning,timesteps):\n",
    "        time_emb = timestep_embedding(timesteps,32)\n",
    "        x = x + self.time_proj(time_emb).unsqueeze(1)\n",
    "        q = self.qlayer(x)\n",
    "        k = self.klayer(conditioning)\n",
    "        v = self.vlayer(conditioning)\n",
    "        attn,_ = self.mha(q,k,v)\n",
    "        attn = self.norm(attn)\n",
    "        return attn\n",
    "    \n",
    "class AttentionEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.down1 = Uattention(inDims = 565,outDims=256)\n",
    "        self.down2 = Uattention(inDims = 256,outDims=128)\n",
    "        self.down3 = Uattention(inDims = 128,outDims=64)\n",
    "    \n",
    "    def forward(self,x, conditioning,timesteps):\n",
    "        \n",
    "        state1 = self.down1(x,conditioning,timesteps)\n",
    "        state2 = self.down2(state1,conditioning,timesteps)\n",
    "        state3 = self.down3(state2,conditioning,timesteps)\n",
    "        return  state1,state2, state3\n",
    "    \n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.up3 = Uattention(inDims=64*2, outDims=128)\n",
    "        self.up2 = Uattention(inDims=128*2, outDims=256)\n",
    "        self.up1 = Uattention(inDims=256*2, outDims=512) # Final dimension matches input\n",
    "        self.final_layer = nn.Linear(512,565)\n",
    "        \n",
    "    def forward(self, x, state1,stat2,state3,conditioning,timesteps):\n",
    "        x = torch.concat([x,state3],dim=-1)\n",
    "        x = self.up3(x,conditioning,timesteps)\n",
    "        x = torch.concat([x,stat2],dim=-1)\n",
    "        x = self.up2(x,conditioning,timesteps)\n",
    "        x = torch.concat([x,state1],dim=-1)\n",
    "        x = self.up1(x,conditioning,timesteps)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "    \n",
    "class AttentionDiffusion(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.noise_scheduler = DDPMScheduler(num_train_timesteps=5000)\n",
    "        self.encoder = AttentionEncoder()\n",
    "        self.latentBlock = nn.Sequential(nn.Linear(64,128),nn.SiLU(),nn.Linear(128,64))\n",
    "        self.decoder = AttentionDecoder()\n",
    "        self.criterion = nn.MSELoss() \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def shared_step(self,batch):\n",
    "        target, inputdata,condition = batch\n",
    "        noise = torch.randn(inputdata.shape)\n",
    "        bs = inputdata.shape[0]\n",
    "        timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps, (bs,), dtype=torch.int64)\n",
    "        noisy_input = self.noise_scheduler.add_noise(inputdata, noise, timesteps)\n",
    "        stat1,stat2,state3 = self.encoder(noisy_input,conditioning=condition,timesteps=timesteps)\n",
    "        x = self.latentBlock(state3)\n",
    "        genes = self.decoder(x,stat1,stat2,state3,conditioning=condition,timesteps=timesteps)\n",
    "        return genes, target   \n",
    "    \n",
    "    def training_step(self, batch,batch_idx):\n",
    "        genes, target = self.shared_step(batch)\n",
    "        loss = self.criterion(genes, target)\n",
    "        self.log(\"train/loss\", loss,prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        genes,target = self.shared_step(batch)\n",
    "        loss = self.criterion(genes, target)\n",
    "        self.log(\"val/loss\", loss,prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d22beb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionDiffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1c268c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | encoder     | AttentionEncoder | 602 K \n",
      "1 | latentBlock | Sequential       | 16.6 K\n",
      "2 | decoder     | AttentionDecoder | 2.1 M \n",
      "3 | criterion   | MSELoss          | 0     \n",
      "-------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12%|█▏        | 350/2862 [00:52<06:17,  6.65it/s, loss=0.884, v_num=15, val/loss=1.9, train/loss=0.887]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=cfg.epochs)\n",
    "trainer.fit(model,train_loader,val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f14d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27aa37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vcell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
